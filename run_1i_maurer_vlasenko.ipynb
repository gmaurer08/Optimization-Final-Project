{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbUOx2UYNtf1"
      },
      "source": [
        "# Optimization Methods For Data Science\n",
        "## Final Project - Part 2: SVM\n",
        "\n",
        "Géraldine V. Maurer, Viktoriia Vlasenko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from functions_1j_maurer_vlasenko import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvPqrN1ht4EO"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "yZX0PhP1t3jH",
        "outputId": "f0b31afb-a1df-4766-e019-0cfeaf5701c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_1</th>\n",
              "      <th>feat_2</th>\n",
              "      <th>feat_3</th>\n",
              "      <th>feat_4</th>\n",
              "      <th>feat_5</th>\n",
              "      <th>feat_6</th>\n",
              "      <th>feat_7</th>\n",
              "      <th>feat_8</th>\n",
              "      <th>feat_9</th>\n",
              "      <th>feat_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_24</th>\n",
              "      <th>feat_25</th>\n",
              "      <th>feat_26</th>\n",
              "      <th>feat_27</th>\n",
              "      <th>feat_28</th>\n",
              "      <th>feat_29</th>\n",
              "      <th>feat_30</th>\n",
              "      <th>feat_31</th>\n",
              "      <th>feat_32</th>\n",
              "      <th>gt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.686191</td>\n",
              "      <td>-0.989465</td>\n",
              "      <td>-0.920503</td>\n",
              "      <td>1.607427</td>\n",
              "      <td>-0.896248</td>\n",
              "      <td>1.118974</td>\n",
              "      <td>-0.969456</td>\n",
              "      <td>1.811707</td>\n",
              "      <td>2.560955</td>\n",
              "      <td>3.803463</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.862891</td>\n",
              "      <td>-0.909545</td>\n",
              "      <td>-0.915361</td>\n",
              "      <td>-0.952061</td>\n",
              "      <td>-0.989461</td>\n",
              "      <td>1.911855</td>\n",
              "      <td>1.409705</td>\n",
              "      <td>2.303997</td>\n",
              "      <td>-0.981840</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.887917</td>\n",
              "      <td>4.915272</td>\n",
              "      <td>-0.939446</td>\n",
              "      <td>-0.343677</td>\n",
              "      <td>-0.964685</td>\n",
              "      <td>-0.478649</td>\n",
              "      <td>4.342395</td>\n",
              "      <td>-0.332870</td>\n",
              "      <td>-0.768041</td>\n",
              "      <td>-0.815375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.939201</td>\n",
              "      <td>-0.965917</td>\n",
              "      <td>-0.969461</td>\n",
              "      <td>-0.934799</td>\n",
              "      <td>5.304822</td>\n",
              "      <td>0.934790</td>\n",
              "      <td>-0.410701</td>\n",
              "      <td>0.284690</td>\n",
              "      <td>4.919212</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.923215</td>\n",
              "      <td>2.746968</td>\n",
              "      <td>-0.918085</td>\n",
              "      <td>0.047804</td>\n",
              "      <td>-0.908587</td>\n",
              "      <td>-0.451752</td>\n",
              "      <td>2.984481</td>\n",
              "      <td>0.535007</td>\n",
              "      <td>-0.591029</td>\n",
              "      <td>-0.324043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.809726</td>\n",
              "      <td>-0.929934</td>\n",
              "      <td>-0.891814</td>\n",
              "      <td>-0.881796</td>\n",
              "      <td>3.415373</td>\n",
              "      <td>1.044108</td>\n",
              "      <td>-0.442615</td>\n",
              "      <td>0.033648</td>\n",
              "      <td>2.628199</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.268866</td>\n",
              "      <td>-0.408416</td>\n",
              "      <td>-0.935145</td>\n",
              "      <td>0.731800</td>\n",
              "      <td>-0.922438</td>\n",
              "      <td>0.221781</td>\n",
              "      <td>-0.046606</td>\n",
              "      <td>1.149634</td>\n",
              "      <td>0.592136</td>\n",
              "      <td>1.357959</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.834968</td>\n",
              "      <td>-0.937475</td>\n",
              "      <td>-0.917737</td>\n",
              "      <td>-0.929519</td>\n",
              "      <td>-0.226282</td>\n",
              "      <td>1.608048</td>\n",
              "      <td>0.276169</td>\n",
              "      <td>1.246468</td>\n",
              "      <td>-0.363367</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.529231</td>\n",
              "      <td>-0.829957</td>\n",
              "      <td>-0.897425</td>\n",
              "      <td>0.921280</td>\n",
              "      <td>-0.865304</td>\n",
              "      <td>0.331018</td>\n",
              "      <td>-0.644940</td>\n",
              "      <td>1.296097</td>\n",
              "      <td>1.166863</td>\n",
              "      <td>2.036034</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775411</td>\n",
              "      <td>-0.881967</td>\n",
              "      <td>-0.864018</td>\n",
              "      <td>-0.908001</td>\n",
              "      <td>-0.784495</td>\n",
              "      <td>1.329586</td>\n",
              "      <td>0.547925</td>\n",
              "      <td>1.195395</td>\n",
              "      <td>-0.810089</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
              "0  2.686191 -0.989465 -0.920503  1.607427 -0.896248  1.118974 -0.969456   \n",
              "1 -0.887917  4.915272 -0.939446 -0.343677 -0.964685 -0.478649  4.342395   \n",
              "2 -0.923215  2.746968 -0.918085  0.047804 -0.908587 -0.451752  2.984481   \n",
              "3 -0.268866 -0.408416 -0.935145  0.731800 -0.922438  0.221781 -0.046606   \n",
              "4  0.529231 -0.829957 -0.897425  0.921280 -0.865304  0.331018 -0.644940   \n",
              "\n",
              "     feat_8    feat_9   feat_10  ...   feat_24   feat_25   feat_26   feat_27  \\\n",
              "0  1.811707  2.560955  3.803463  ... -0.862891 -0.909545 -0.915361 -0.952061   \n",
              "1 -0.332870 -0.768041 -0.815375  ... -0.939201 -0.965917 -0.969461 -0.934799   \n",
              "2  0.535007 -0.591029 -0.324043  ... -0.809726 -0.929934 -0.891814 -0.881796   \n",
              "3  1.149634  0.592136  1.357959  ... -0.834968 -0.937475 -0.917737 -0.929519   \n",
              "4  1.296097  1.166863  2.036034  ... -0.775411 -0.881967 -0.864018 -0.908001   \n",
              "\n",
              "    feat_28   feat_29   feat_30   feat_31   feat_32  gt  \n",
              "0 -0.989461  1.911855  1.409705  2.303997 -0.981840  54  \n",
              "1  5.304822  0.934790 -0.410701  0.284690  4.919212  18  \n",
              "2  3.415373  1.044108 -0.442615  0.033648  2.628199  26  \n",
              "3 -0.226282  1.608048  0.276169  1.246468 -0.363367  33  \n",
              "4 -0.784495  1.329586  0.547925  1.195395 -0.810089  35  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/gmaurer08/Optimization-Final-Project/refs/heads/main/AGE_PREDICTION.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDmGTiXxuBsj"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-lH4rJruU2L",
        "outputId": "12f6dc76-8366-464a-bf30-06df76d89ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Data shape: (20475, 32)\n",
            "Target range: 10.00-89.00\n",
            "Train set: (16380, 32)\n",
            "Test set: (4095, 32)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target\n",
        "feature_cols = [col for col in data.columns if col.startswith('feat')]\n",
        "X = data[feature_cols].values\n",
        "y = data['gt'].values\n",
        "\n",
        "print(f\"Features: {len(feature_cols)} columns\")\n",
        "print(f\"Data shape: {X.shape}\")\n",
        "print(f\"Target range: {y.min():.2f}-{y.max():.2f}\")\n",
        "\n",
        "# Split data into train/test sets\n",
        "n_total = len(X)\n",
        "n_train = int(0.8*n_total)    # 80% for training (used with CV inside)\n",
        "# Remaining 20% for testing\n",
        "\n",
        "# Shuffle indices\n",
        "indices = np.random.permutation(n_total)\n",
        "train_idx = indices[:n_train]\n",
        "test_idx = indices[n_train:]\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "# Normalize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Train set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd8YES8Sunh_"
      },
      "source": [
        "### Find the best hyperparameters with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhoxaNNHum51",
        "outputId": "72dbf347-c18b-4579-9c33-2987f2f56f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting hyperparameter search\n",
            "\n",
            "[1/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1647.938274\n",
            "Final loss: 85.693057\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 83.5729, Val Loss: 100.7404\n",
            "Train MAPE: 21.5956%, Val MAPE: 23.4847%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1660.407392\n",
            "Final loss: 85.110326\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 82.3211, Val Loss: 100.6778\n",
            "Train MAPE: 21.1363%, Val MAPE: 23.8377%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1693.929907\n",
            "Final loss: 83.498651\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 80.7236, Val Loss: 103.7025\n",
            "Train MAPE: 21.0520%, Val MAPE: 23.9442%\n",
            "Results: Val Loss = 101.7069, Val MAPE = 23.7555%\n",
            "\n",
            "[2/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1644.061885\n",
            "Final loss: 92.736047\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.4903, Val Loss: 95.4288\n",
            "Train MAPE: 22.3852%, Val MAPE: 22.9808%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1679.841634\n",
            "Final loss: 93.900688\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.1655, Val Loss: 92.6190\n",
            "Train MAPE: 22.3905%, Val MAPE: 22.9467%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1689.265481\n",
            "Final loss: 91.871810\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.6502, Val Loss: 96.7000\n",
            "Train MAPE: 22.1773%, Val MAPE: 23.1924%\n",
            "Results: Val Loss = 94.9159, Val MAPE = 23.0400%\n",
            "\n",
            "[3/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1673.453981\n",
            "Final loss: 97.955772\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.4825, Val Loss: 95.1937\n",
            "Train MAPE: 23.2613%, Val MAPE: 23.2701%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1689.587813\n",
            "Final loss: 99.007704\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 95.5596, Val Loss: 93.6650\n",
            "Train MAPE: 23.3677%, Val MAPE: 23.2274%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1710.221647\n",
            "Final loss: 97.683375\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.0357, Val Loss: 96.5811\n",
            "Train MAPE: 23.1921%, Val MAPE: 23.4344%\n",
            "Results: Val Loss = 95.1466, Val MAPE = 23.3106%\n",
            "\n",
            "[4/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1754.776795\n",
            "Final loss: 91.092870\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.1578, Val Loss: 96.7000\n",
            "Train MAPE: 22.3796%, Val MAPE: 23.1675%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1715.979890\n",
            "Final loss: 92.377079\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.4560, Val Loss: 93.0882\n",
            "Train MAPE: 22.3354%, Val MAPE: 23.0330%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1743.382749\n",
            "Final loss: 90.043310\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 87.6876, Val Loss: 97.5591\n",
            "Train MAPE: 22.0578%, Val MAPE: 23.3058%\n",
            "Results: Val Loss = 95.7824, Val MAPE = 23.1688%\n",
            "\n",
            "[5/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1642.068264\n",
            "Final loss: 96.123612\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.7707, Val Loss: 94.9531\n",
            "Train MAPE: 23.1292%, Val MAPE: 23.1944%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1634.614455\n",
            "Final loss: 97.105446\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.9195, Val Loss: 93.1659\n",
            "Train MAPE: 23.2565%, Val MAPE: 23.1055%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1642.373150\n",
            "Final loss: 95.524832\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.1681, Val Loss: 96.0467\n",
            "Train MAPE: 23.0221%, Val MAPE: 23.3493%\n",
            "Results: Val Loss = 94.7219, Val MAPE = 23.2164%\n",
            "\n",
            "[6/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1660.350379\n",
            "Final loss: 108.317090\n",
            "Optimization successful: True\n",
            "Number of iterations: 610\n",
            "Train Loss: 97.4544, Val Loss: 97.1975\n",
            "Train MAPE: 23.7048%, Val MAPE: 23.6304%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1630.870962\n",
            "Final loss: 108.826388\n",
            "Optimization successful: True\n",
            "Number of iterations: 516\n",
            "Train Loss: 97.9737, Val Loss: 96.2005\n",
            "Train MAPE: 23.7550%, Val MAPE: 23.6567%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1747.540776\n",
            "Final loss: 107.404342\n",
            "Optimization successful: True\n",
            "Number of iterations: 512\n",
            "Train Loss: 96.4976, Val Loss: 99.0186\n",
            "Train MAPE: 23.5923%, Val MAPE: 23.8011%\n",
            "Results: Val Loss = 97.4722, Val MAPE = 23.6961%\n",
            "\n",
            "[7/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1699.992864\n",
            "Final loss: 82.635637\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 78.8875, Val Loss: 105.2829\n",
            "Train MAPE: 21.0073%, Val MAPE: 23.9796%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1681.469462\n",
            "Final loss: 82.316976\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 78.6946, Val Loss: 103.5016\n",
            "Train MAPE: 20.5775%, Val MAPE: 24.0957%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1699.769593\n",
            "Final loss: 78.246230\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 73.6661, Val Loss: 111.5078\n",
            "Train MAPE: 19.9749%, Val MAPE: 24.8061%\n",
            "Results: Val Loss = 106.7641, Val MAPE = 24.2938%\n",
            "\n",
            "[8/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1647.304508\n",
            "Final loss: 92.568938\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.0313, Val Loss: 95.2380\n",
            "Train MAPE: 22.4341%, Val MAPE: 22.9692%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1708.998376\n",
            "Final loss: 93.610079\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.1381, Val Loss: 92.8350\n",
            "Train MAPE: 22.3867%, Val MAPE: 22.9669%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1681.954670\n",
            "Final loss: 91.659451\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.6833, Val Loss: 96.7707\n",
            "Train MAPE: 22.1783%, Val MAPE: 23.1553%\n",
            "Results: Val Loss = 94.9479, Val MAPE = 23.0305%\n",
            "\n",
            "[9/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1681.707106\n",
            "Final loss: 97.013736\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.4523, Val Loss: 95.1479\n",
            "Train MAPE: 23.2406%, Val MAPE: 23.2477%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1689.190668\n",
            "Final loss: 97.890753\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 95.4916, Val Loss: 93.5533\n",
            "Train MAPE: 23.3392%, Val MAPE: 23.1836%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1700.730949\n",
            "Final loss: 96.376659\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.9697, Val Loss: 96.5098\n",
            "Train MAPE: 23.1633%, Val MAPE: 23.4107%\n",
            "Results: Val Loss = 95.0703, Val MAPE = 23.2807%\n",
            "\n",
            "[10/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1658.555959\n",
            "Final loss: 91.424960\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.7802, Val Loss: 95.8568\n",
            "Train MAPE: 22.4504%, Val MAPE: 23.1069%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1702.159691\n",
            "Final loss: 92.615044\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.6939, Val Loss: 92.9027\n",
            "Train MAPE: 22.3489%, Val MAPE: 23.0407%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1647.955501\n",
            "Final loss: 90.538390\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.5198, Val Loss: 98.0416\n",
            "Train MAPE: 22.2159%, Val MAPE: 23.3777%\n",
            "Results: Val Loss = 95.6004, Val MAPE = 23.1751%\n",
            "\n",
            "[11/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1776.780561\n",
            "Final loss: 95.714017\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.8138, Val Loss: 94.9766\n",
            "Train MAPE: 23.1146%, Val MAPE: 23.1773%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1709.259507\n",
            "Final loss: 96.705520\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.9641, Val Loss: 93.1299\n",
            "Train MAPE: 23.2562%, Val MAPE: 23.1015%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1586.305565\n",
            "Final loss: 95.131162\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.2679, Val Loss: 96.0647\n",
            "Train MAPE: 23.0207%, Val MAPE: 23.3348%\n",
            "Results: Val Loss = 94.7238, Val MAPE = 23.2045%\n",
            "\n",
            "[12/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1643.498136\n",
            "Final loss: 104.749414\n",
            "Optimization successful: True\n",
            "Number of iterations: 497\n",
            "Train Loss: 96.8172, Val Loss: 96.5376\n",
            "Train MAPE: 23.6032%, Val MAPE: 23.5389%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1640.224142\n",
            "Final loss: 105.260576\n",
            "Optimization successful: True\n",
            "Number of iterations: 383\n",
            "Train Loss: 97.3978, Val Loss: 95.5991\n",
            "Train MAPE: 23.6716%, Val MAPE: 23.5396%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1785.143477\n",
            "Final loss: 103.834421\n",
            "Optimization successful: True\n",
            "Number of iterations: 373\n",
            "Train Loss: 95.9225, Val Loss: 98.4344\n",
            "Train MAPE: 23.4996%, Val MAPE: 23.7239%\n",
            "Results: Val Loss = 96.8570, Val MAPE = 23.6008%\n",
            "\n",
            "[13/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1661.070809\n",
            "Final loss: 86.123523\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 84.6973, Val Loss: 98.8969\n",
            "Train MAPE: 21.6374%, Val MAPE: 23.4232%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1690.495226\n",
            "Final loss: 92.127035\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.3130, Val Loss: 95.9029\n",
            "Train MAPE: 22.5671%, Val MAPE: 23.2159%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1691.085870\n",
            "Final loss: 90.980804\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.7548, Val Loss: 97.9691\n",
            "Train MAPE: 22.4515%, Val MAPE: 23.3777%\n",
            "Results: Val Loss = 97.5896, Val MAPE = 23.3389%\n",
            "\n",
            "[14/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1640.170706\n",
            "Final loss: 94.142481\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.4313, Val Loss: 95.8446\n",
            "Train MAPE: 22.5763%, Val MAPE: 22.9989%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1680.982160\n",
            "Final loss: 93.199363\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.6606, Val Loss: 94.6536\n",
            "Train MAPE: 22.1646%, Val MAPE: 23.0935%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1698.511734\n",
            "Final loss: 91.557036\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 87.3540, Val Loss: 98.5144\n",
            "Train MAPE: 21.9978%, Val MAPE: 23.3836%\n",
            "Results: Val Loss = 96.3376, Val MAPE = 23.1587%\n",
            "\n",
            "[15/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1680.781503\n",
            "Final loss: 101.738508\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.5361, Val Loss: 95.6087\n",
            "Train MAPE: 23.3336%, Val MAPE: 23.3518%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1648.582534\n",
            "Final loss: 100.636287\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 95.3315, Val Loss: 93.6205\n",
            "Train MAPE: 23.3654%, Val MAPE: 23.2654%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1703.743137\n",
            "Final loss: 100.608736\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.8528, Val Loss: 96.8226\n",
            "Train MAPE: 23.2199%, Val MAPE: 23.4956%\n",
            "Results: Val Loss = 95.3506, Val MAPE = 23.3709%\n",
            "\n",
            "[16/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1638.103032\n",
            "Final loss: 91.807358\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.3326, Val Loss: 96.1559\n",
            "Train MAPE: 22.5312%, Val MAPE: 23.0923%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1702.910030\n",
            "Final loss: 91.872451\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.0851, Val Loss: 94.2618\n",
            "Train MAPE: 22.2855%, Val MAPE: 23.0777%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1735.440639\n",
            "Final loss: 89.526933\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 87.3017, Val Loss: 98.4483\n",
            "Train MAPE: 22.0460%, Val MAPE: 23.3169%\n",
            "Results: Val Loss = 96.2887, Val MAPE = 23.1623%\n",
            "\n",
            "[17/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1668.229231\n",
            "Final loss: 96.916167\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 92.7450, Val Loss: 94.8989\n",
            "Train MAPE: 22.9980%, Val MAPE: 23.1480%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1653.570616\n",
            "Final loss: 98.013122\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.4697, Val Loss: 92.9625\n",
            "Train MAPE: 23.2190%, Val MAPE: 23.1057%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1716.681842\n",
            "Final loss: 96.344919\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 92.5219, Val Loss: 96.0303\n",
            "Train MAPE: 22.9708%, Val MAPE: 23.3568%\n",
            "Results: Val Loss = 94.6306, Val MAPE = 23.2035%\n",
            "\n",
            "[18/24] Testing configuration:\n",
            "Layers: [64, 32, 16] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1704.565956\n",
            "Final loss: 116.742195\n",
            "Optimization successful: True\n",
            "Number of iterations: 540\n",
            "Train Loss: 99.2924, Val Loss: 99.1622\n",
            "Train MAPE: 23.9829%, Val MAPE: 23.8811%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1670.318994\n",
            "Final loss: 117.272030\n",
            "Optimization successful: True\n",
            "Number of iterations: 549\n",
            "Train Loss: 99.6882, Val Loss: 97.9509\n",
            "Train MAPE: 24.0115%, Val MAPE: 23.9649%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 16, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1697.629196\n",
            "Final loss: 115.903242\n",
            "Optimization successful: True\n",
            "Number of iterations: 503\n",
            "Train Loss: 98.3033, Val Loss: 100.7566\n",
            "Train MAPE: 23.8680%, Val MAPE: 24.0676%\n",
            "Results: Val Loss = 99.2899, Val MAPE = 23.9712%\n",
            "\n",
            "[19/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1667.950611\n",
            "Final loss: 82.569584\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 80.4878, Val Loss: 103.4868\n",
            "Train MAPE: 21.0330%, Val MAPE: 23.8992%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1676.722688\n",
            "Final loss: 84.565026\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 82.4380, Val Loss: 100.8623\n",
            "Train MAPE: 21.1370%, Val MAPE: 23.8060%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1713.100843\n",
            "Final loss: 84.864001\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 83.3689, Val Loss: 102.7497\n",
            "Train MAPE: 21.4013%, Val MAPE: 23.5926%\n",
            "Results: Val Loss = 102.3663, Val MAPE = 23.7660%\n",
            "\n",
            "[20/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1677.315822\n",
            "Final loss: 92.562476\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.6764, Val Loss: 96.5611\n",
            "Train MAPE: 22.4399%, Val MAPE: 23.1291%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1655.082386\n",
            "Final loss: 93.754880\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.0417, Val Loss: 93.6266\n",
            "Train MAPE: 22.4049%, Val MAPE: 23.0791%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1703.189995\n",
            "Final loss: 90.519049\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 86.7508, Val Loss: 99.3426\n",
            "Train MAPE: 21.8872%, Val MAPE: 23.3635%\n",
            "Results: Val Loss = 96.5101, Val MAPE = 23.1906%\n",
            "\n",
            "[21/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1689.272242\n",
            "Final loss: 97.924875\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.8487, Val Loss: 95.1054\n",
            "Train MAPE: 23.1792%, Val MAPE: 23.2202%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1691.861048\n",
            "Final loss: 98.778727\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 95.0492, Val Loss: 93.2842\n",
            "Train MAPE: 23.2979%, Val MAPE: 23.1787%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1707.444868\n",
            "Final loss: 97.249536\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.3525, Val Loss: 96.1777\n",
            "Train MAPE: 23.1016%, Val MAPE: 23.3794%\n",
            "Results: Val Loss = 94.8558, Val MAPE = 23.2594%\n",
            "\n",
            "[22/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1743.132239\n",
            "Final loss: 91.361603\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.9220, Val Loss: 95.9898\n",
            "Train MAPE: 22.4983%, Val MAPE: 23.1286%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1725.289804\n",
            "Final loss: 92.583443\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.0994, Val Loss: 93.2651\n",
            "Train MAPE: 22.4245%, Val MAPE: 23.0301%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1632.705695\n",
            "Final loss: 89.913031\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.1087, Val Loss: 97.9455\n",
            "Train MAPE: 22.0673%, Val MAPE: 23.3000%\n",
            "Results: Val Loss = 95.7335, Val MAPE = 23.1529%\n",
            "\n",
            "[23/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1695.754037\n",
            "Final loss: 96.134280\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.0789, Val Loss: 94.8414\n",
            "Train MAPE: 23.0166%, Val MAPE: 23.1488%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1769.048228\n",
            "Final loss: 97.195090\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.4982, Val Loss: 92.8362\n",
            "Train MAPE: 23.1893%, Val MAPE: 23.0607%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1661.502889\n",
            "Final loss: 95.584524\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 92.7008, Val Loss: 95.9024\n",
            "Train MAPE: 22.9507%, Val MAPE: 23.3130%\n",
            "Results: Val Loss = 94.5266, Val MAPE = 23.1742%\n",
            "\n",
            "[24/24] Testing configuration:\n",
            "Layers: [128, 64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1753.530506\n",
            "Final loss: 110.591465\n",
            "Optimization successful: True\n",
            "Number of iterations: 405\n",
            "Train Loss: 97.9287, Val Loss: 97.6121\n",
            "Train MAPE: 23.7561%, Val MAPE: 23.6704%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1672.804315\n",
            "Final loss: 111.061457\n",
            "Optimization successful: True\n",
            "Number of iterations: 353\n",
            "Train Loss: 98.3439, Val Loss: 96.6219\n",
            "Train MAPE: 23.8045%, Val MAPE: 23.7064%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1792.820494\n",
            "Final loss: 109.641318\n",
            "Optimization successful: True\n",
            "Number of iterations: 376\n",
            "Train Loss: 96.8862, Val Loss: 99.4454\n",
            "Train MAPE: 23.6410%, Val MAPE: 23.8647%\n",
            "Results: Val Loss = 97.8931, Val MAPE = 23.7472%\n",
            "\n",
            "\n",
            "HYPERPARAMETER SEARCH COMPLETE\n",
            "Best validation loss: 94.526646\n",
            "Best configuration:\n",
            "Hidden layers: [128, 64, 32]\n",
            "Activations: sigmoid\n",
            "Lambda: 0.01\n"
          ]
        }
      ],
      "source": [
        "# Find best hyperparameters using cross-validation\n",
        "best_parameters, search_results = hyperparameter_search(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-8c4C5duvAB"
      },
      "source": [
        "### Training the final model with the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJsFXLw-u9rx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training network with architecture: [32, 128, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1603.291428\n",
            "Final loss: 96.475317\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "\n",
            "Optimization details:\n",
            "Success: False\n",
            "Message: STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "Iterations: 1000\n",
            "Loss reduction: 1603.291428 -> 96.475317\n"
          ]
        }
      ],
      "source": [
        "# Train final model with best parameters\n",
        "final_weights, final_biases, optimization_result, initial_loss, final_loss = train_network(\n",
        "    X_train, y_train,\n",
        "    layer_sizes=best_parameters['layers'],\n",
        "    activation=best_parameters['activation'],\n",
        "    lambda_reg=best_parameters['lambda_reg'],\n",
        "    method='L-BFGS-B',\n",
        "    maxiter=1000\n",
        ")\n",
        "\n",
        "print(f\"\\nOptimization details:\")\n",
        "print(f\"Success: {optimization_result.success}\")\n",
        "print(f\"Message: {optimization_result.message}\")\n",
        "print(f\"Iterations: {optimization_result.nit}\")\n",
        "print(f\"Loss reduction: {initial_loss:.6f} -> {final_loss:.6f}\")\n",
        "\n",
        "# Make predictions on all datasets\n",
        "y_train_pred = predict(X_train, final_weights, final_biases, best_parameters['activation'])\n",
        "y_test_pred = predict(X_test, final_weights, final_biases, best_parameters['activation'])\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Absolute Percentage Error\n",
        "train_mape = MAPE(y_train, y_train_pred)\n",
        "test_mape = MAPE(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI8IfwTUw3SI"
      },
      "source": [
        "### Print Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O_C8DE9BtrxZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Network Configuration:\n",
            "Architecture: [32, 128, 64, 32, 1]\n",
            "Hidden layers: [128, 64, 32]\n",
            "Activation function: sigmoid\n",
            "Regularization (lambda): 0.01\n",
            "Total parameters: 14593\n",
            "\n",
            "Optimization Results:\n",
            "Method: L-BFGS-B\n",
            "Max iterations: 1000\n",
            "Convergence: Failed\n",
            "Iterations used: 1000\n",
            "Initial loss: 1603.291428\n",
            "Final loss: 96.475317\n",
            "Loss reduction: 93.98%\n",
            "\n",
            "Performance Metrics:\n",
            "Training MSE: 93.811015\n",
            "Test MSE: 97.675791\n",
            "Training MAPE: 23.1015%\n",
            "Test MAPE: 23.9690%\n",
            "\n",
            "Model Insights:\n",
            "Best performing activation: sigmoid\n",
            "Optimal regularization strength: 0.01\n",
            "Network depth: 4 layers\n",
            "Network width: 128 neurons (max)\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nBest Network Configuration:\")\n",
        "print(f\"Architecture: {best_parameters['layers']}\")\n",
        "print(f\"Hidden layers: {best_parameters['layers'][1:-1]}\")\n",
        "print(f\"Activation function: {best_parameters['activation']}\")\n",
        "print(f\"Regularization (lambda): {best_parameters['lambda_reg']}\")\n",
        "print(f\"Total parameters: {sum(w.size + b.size for w, b in zip(final_weights, final_biases))}\")\n",
        "\n",
        "print(f\"\\nOptimization Results:\")\n",
        "print(f\"Method: L-BFGS-B\")\n",
        "print(f\"Max iterations: 1000\")\n",
        "print(f\"Convergence: {'Successful' if optimization_result.success else 'Failed'}\")\n",
        "print(f\"Iterations used: {optimization_result.nit}\")\n",
        "print(f\"Initial loss: {initial_loss:.6f}\")\n",
        "print(f\"Final loss: {final_loss:.6f}\")\n",
        "print(f\"Loss reduction: {((initial_loss - final_loss) / initial_loss * 100):.2f}%\")\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"Training MSE: {train_mse:.6f}\")\n",
        "print(f\"Test MSE: {test_mse:.6f}\")\n",
        "print(f\"Training MAPE: {train_mape:.4f}%\")\n",
        "print(f\"Test MAPE: {test_mape:.4f}%\")\n",
        "\n",
        "print(f\"\\nModel Insights:\")\n",
        "print(f\"Best performing activation: {best_parameters['activation']}\")\n",
        "print(f\"Optimal regularization strength: {best_parameters['lambda_reg']}\")\n",
        "print(f\"Network depth: {len(best_parameters['layers'])-1} layers\")\n",
        "print(f\"Network width: {max(best_parameters['layers'][1:-1])} neurons (max)\")\n",
        "\n",
        "\n",
        "# Save detailed results\n",
        "results_summary = {\n",
        "    'best_config': best_parameters,\n",
        "    'optimization_result': {\n",
        "        'success': optimization_result.success,\n",
        "        'message': optimization_result.message,\n",
        "        'iterations': optimization_result.nit,\n",
        "        'initial_loss': initial_loss,\n",
        "        'final_loss': final_loss\n",
        "    },\n",
        "    'performance_metrics': {\n",
        "        'train_mse': train_mse,\n",
        "        'test_mse': test_mse,\n",
        "        'train_mape': train_mape,\n",
        "        'test_mape': test_mape\n",
        "    },\n",
        "    'hyperparameter_search_results': search_results\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"results_summary.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results_summary,f)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
