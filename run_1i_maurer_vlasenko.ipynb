{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbUOx2UYNtf1"
      },
      "source": [
        "# Optimization Methods For Data Science\n",
        "## Final Project - Part 2: SVM\n",
        "\n",
        "Géraldine V. Maurer, Viktoriia Vlasenko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from functions_1j_maurer_vlasenko import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvPqrN1ht4EO"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "yZX0PhP1t3jH",
        "outputId": "f0b31afb-a1df-4766-e019-0cfeaf5701c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_1</th>\n",
              "      <th>feat_2</th>\n",
              "      <th>feat_3</th>\n",
              "      <th>feat_4</th>\n",
              "      <th>feat_5</th>\n",
              "      <th>feat_6</th>\n",
              "      <th>feat_7</th>\n",
              "      <th>feat_8</th>\n",
              "      <th>feat_9</th>\n",
              "      <th>feat_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_24</th>\n",
              "      <th>feat_25</th>\n",
              "      <th>feat_26</th>\n",
              "      <th>feat_27</th>\n",
              "      <th>feat_28</th>\n",
              "      <th>feat_29</th>\n",
              "      <th>feat_30</th>\n",
              "      <th>feat_31</th>\n",
              "      <th>feat_32</th>\n",
              "      <th>gt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.686191</td>\n",
              "      <td>-0.989465</td>\n",
              "      <td>-0.920503</td>\n",
              "      <td>1.607427</td>\n",
              "      <td>-0.896248</td>\n",
              "      <td>1.118974</td>\n",
              "      <td>-0.969456</td>\n",
              "      <td>1.811707</td>\n",
              "      <td>2.560955</td>\n",
              "      <td>3.803463</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.862891</td>\n",
              "      <td>-0.909545</td>\n",
              "      <td>-0.915361</td>\n",
              "      <td>-0.952061</td>\n",
              "      <td>-0.989461</td>\n",
              "      <td>1.911855</td>\n",
              "      <td>1.409705</td>\n",
              "      <td>2.303997</td>\n",
              "      <td>-0.981840</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.887917</td>\n",
              "      <td>4.915272</td>\n",
              "      <td>-0.939446</td>\n",
              "      <td>-0.343677</td>\n",
              "      <td>-0.964685</td>\n",
              "      <td>-0.478649</td>\n",
              "      <td>4.342395</td>\n",
              "      <td>-0.332870</td>\n",
              "      <td>-0.768041</td>\n",
              "      <td>-0.815375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.939201</td>\n",
              "      <td>-0.965917</td>\n",
              "      <td>-0.969461</td>\n",
              "      <td>-0.934799</td>\n",
              "      <td>5.304822</td>\n",
              "      <td>0.934790</td>\n",
              "      <td>-0.410701</td>\n",
              "      <td>0.284690</td>\n",
              "      <td>4.919212</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.923215</td>\n",
              "      <td>2.746968</td>\n",
              "      <td>-0.918085</td>\n",
              "      <td>0.047804</td>\n",
              "      <td>-0.908587</td>\n",
              "      <td>-0.451752</td>\n",
              "      <td>2.984481</td>\n",
              "      <td>0.535007</td>\n",
              "      <td>-0.591029</td>\n",
              "      <td>-0.324043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.809726</td>\n",
              "      <td>-0.929934</td>\n",
              "      <td>-0.891814</td>\n",
              "      <td>-0.881796</td>\n",
              "      <td>3.415373</td>\n",
              "      <td>1.044108</td>\n",
              "      <td>-0.442615</td>\n",
              "      <td>0.033648</td>\n",
              "      <td>2.628199</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.268866</td>\n",
              "      <td>-0.408416</td>\n",
              "      <td>-0.935145</td>\n",
              "      <td>0.731800</td>\n",
              "      <td>-0.922438</td>\n",
              "      <td>0.221781</td>\n",
              "      <td>-0.046606</td>\n",
              "      <td>1.149634</td>\n",
              "      <td>0.592136</td>\n",
              "      <td>1.357959</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.834968</td>\n",
              "      <td>-0.937475</td>\n",
              "      <td>-0.917737</td>\n",
              "      <td>-0.929519</td>\n",
              "      <td>-0.226282</td>\n",
              "      <td>1.608048</td>\n",
              "      <td>0.276169</td>\n",
              "      <td>1.246468</td>\n",
              "      <td>-0.363367</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.529231</td>\n",
              "      <td>-0.829957</td>\n",
              "      <td>-0.897425</td>\n",
              "      <td>0.921280</td>\n",
              "      <td>-0.865304</td>\n",
              "      <td>0.331018</td>\n",
              "      <td>-0.644940</td>\n",
              "      <td>1.296097</td>\n",
              "      <td>1.166863</td>\n",
              "      <td>2.036034</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775411</td>\n",
              "      <td>-0.881967</td>\n",
              "      <td>-0.864018</td>\n",
              "      <td>-0.908001</td>\n",
              "      <td>-0.784495</td>\n",
              "      <td>1.329586</td>\n",
              "      <td>0.547925</td>\n",
              "      <td>1.195395</td>\n",
              "      <td>-0.810089</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
              "0  2.686191 -0.989465 -0.920503  1.607427 -0.896248  1.118974 -0.969456   \n",
              "1 -0.887917  4.915272 -0.939446 -0.343677 -0.964685 -0.478649  4.342395   \n",
              "2 -0.923215  2.746968 -0.918085  0.047804 -0.908587 -0.451752  2.984481   \n",
              "3 -0.268866 -0.408416 -0.935145  0.731800 -0.922438  0.221781 -0.046606   \n",
              "4  0.529231 -0.829957 -0.897425  0.921280 -0.865304  0.331018 -0.644940   \n",
              "\n",
              "     feat_8    feat_9   feat_10  ...   feat_24   feat_25   feat_26   feat_27  \\\n",
              "0  1.811707  2.560955  3.803463  ... -0.862891 -0.909545 -0.915361 -0.952061   \n",
              "1 -0.332870 -0.768041 -0.815375  ... -0.939201 -0.965917 -0.969461 -0.934799   \n",
              "2  0.535007 -0.591029 -0.324043  ... -0.809726 -0.929934 -0.891814 -0.881796   \n",
              "3  1.149634  0.592136  1.357959  ... -0.834968 -0.937475 -0.917737 -0.929519   \n",
              "4  1.296097  1.166863  2.036034  ... -0.775411 -0.881967 -0.864018 -0.908001   \n",
              "\n",
              "    feat_28   feat_29   feat_30   feat_31   feat_32  gt  \n",
              "0 -0.989461  1.911855  1.409705  2.303997 -0.981840  54  \n",
              "1  5.304822  0.934790 -0.410701  0.284690  4.919212  18  \n",
              "2  3.415373  1.044108 -0.442615  0.033648  2.628199  26  \n",
              "3 -0.226282  1.608048  0.276169  1.246468 -0.363367  33  \n",
              "4 -0.784495  1.329586  0.547925  1.195395 -0.810089  35  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/gmaurer08/Optimization-Final-Project/refs/heads/main/AGE_PREDICTION.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDmGTiXxuBsj"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-lH4rJruU2L",
        "outputId": "12f6dc76-8366-464a-bf30-06df76d89ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: 32 columns\n",
            "Data shape: (20475, 32)\n",
            "Target range: 10.00-89.00\n",
            "Train set: (16380, 32)\n",
            "Test set: (4095, 32)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target\n",
        "feature_cols = [col for col in data.columns if col.startswith('feat')]\n",
        "X = data[feature_cols].values\n",
        "y = data['gt'].values\n",
        "\n",
        "print(f\"Features: {len(feature_cols)} columns\")\n",
        "print(f\"Data shape: {X.shape}\")\n",
        "print(f\"Target range: {y.min():.2f}-{y.max():.2f}\")\n",
        "\n",
        "# Split data into train/test sets\n",
        "n_total = len(X)\n",
        "n_train = int(0.8*n_total)    # 80% for training (used with CV inside)\n",
        "# Remaining 20% for testing\n",
        "\n",
        "# Shuffle indices\n",
        "indices = np.random.permutation(n_total)\n",
        "train_idx = indices[:n_train]\n",
        "test_idx = indices[n_train:]\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "# Normalize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Train set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd8YES8Sunh_"
      },
      "source": [
        "### Find the best hyperparameters with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhoxaNNHum51",
        "outputId": "72dbf347-c18b-4579-9c33-2987f2f56f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting hyperparameter search\n",
            "\n",
            "[1/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1647.938274\n",
            "Final loss: 85.693057\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 83.5729, Val Loss: 100.7404\n",
            "Train MAPE: 21.5956%, Val MAPE: 23.4847%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1660.407392\n",
            "Final loss: 85.110326\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 82.3211, Val Loss: 100.6778\n",
            "Train MAPE: 21.1363%, Val MAPE: 23.8377%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1693.929907\n",
            "Final loss: 83.498651\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 80.7236, Val Loss: 103.7025\n",
            "Train MAPE: 21.0520%, Val MAPE: 23.9442%\n",
            "Results: Val Loss = 101.7069, Val MAPE = 23.7555%\n",
            "\n",
            "[2/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1644.061885\n",
            "Final loss: 92.736047\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.4903, Val Loss: 95.4288\n",
            "Train MAPE: 22.3852%, Val MAPE: 22.9808%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1679.841634\n",
            "Final loss: 93.900688\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.1655, Val Loss: 92.6190\n",
            "Train MAPE: 22.3905%, Val MAPE: 22.9467%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1689.265481\n",
            "Final loss: 91.871810\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.6502, Val Loss: 96.7000\n",
            "Train MAPE: 22.1773%, Val MAPE: 23.1924%\n",
            "Results: Val Loss = 94.9159, Val MAPE = 23.0400%\n",
            "\n",
            "[3/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1673.453981\n",
            "Final loss: 97.955772\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.4825, Val Loss: 95.1937\n",
            "Train MAPE: 23.2613%, Val MAPE: 23.2701%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1689.587813\n",
            "Final loss: 99.007704\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 95.5596, Val Loss: 93.6650\n",
            "Train MAPE: 23.3677%, Val MAPE: 23.2274%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1710.221647\n",
            "Final loss: 97.683375\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.0357, Val Loss: 96.5811\n",
            "Train MAPE: 23.1921%, Val MAPE: 23.4344%\n",
            "Results: Val Loss = 95.1466, Val MAPE = 23.3106%\n",
            "\n",
            "[4/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1754.776795\n",
            "Final loss: 91.092870\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 89.1578, Val Loss: 96.7000\n",
            "Train MAPE: 22.3796%, Val MAPE: 23.1675%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1715.979890\n",
            "Final loss: 92.377079\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.4560, Val Loss: 93.0882\n",
            "Train MAPE: 22.3354%, Val MAPE: 23.0330%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.001\n",
            "Initial loss: 1743.382749\n",
            "Final loss: 90.043310\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 87.6876, Val Loss: 97.5591\n",
            "Train MAPE: 22.0578%, Val MAPE: 23.3058%\n",
            "Results: Val Loss = 95.7824, Val MAPE = 23.1688%\n",
            "\n",
            "[5/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1642.068264\n",
            "Final loss: 96.123612\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.7707, Val Loss: 94.9531\n",
            "Train MAPE: 23.1292%, Val MAPE: 23.1944%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1634.614455\n",
            "Final loss: 97.105446\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 94.9195, Val Loss: 93.1659\n",
            "Train MAPE: 23.2565%, Val MAPE: 23.1055%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.01\n",
            "Initial loss: 1642.373150\n",
            "Final loss: 95.524832\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 93.1681, Val Loss: 96.0467\n",
            "Train MAPE: 23.0221%, Val MAPE: 23.3493%\n",
            "Results: Val Loss = 94.7219, Val MAPE = 23.2164%\n",
            "\n",
            "[6/24] Testing configuration:\n",
            "Layers: [64, 32] (hidden)\n",
            "Activation: sigmoid\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1660.350379\n",
            "Final loss: 108.317090\n",
            "Optimization successful: True\n",
            "Number of iterations: 610\n",
            "Train Loss: 97.4544, Val Loss: 97.1975\n",
            "Train MAPE: 23.7048%, Val MAPE: 23.6304%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1630.870962\n",
            "Final loss: 108.826388\n",
            "Optimization successful: True\n",
            "Number of iterations: 516\n",
            "Train Loss: 97.9737, Val Loss: 96.2005\n",
            "Train MAPE: 23.7550%, Val MAPE: 23.6567%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 64, 32, 1]\n",
            "Activation: sigmoid, Lambda: 0.1\n",
            "Initial loss: 1747.540776\n",
            "Final loss: 107.404342\n",
            "Optimization successful: True\n",
            "Number of iterations: 512\n",
            "Train Loss: 96.4976, Val Loss: 99.0186\n",
            "Train MAPE: 23.5923%, Val MAPE: 23.8011%\n",
            "Results: Val Loss = 97.4722, Val MAPE = 23.6961%\n",
            "\n",
            "[7/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.001\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1699.992864\n",
            "Final loss: 82.635637\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 78.8875, Val Loss: 105.2829\n",
            "Train MAPE: 21.0073%, Val MAPE: 23.9796%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1681.469462\n",
            "Final loss: 82.316976\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 78.6946, Val Loss: 103.5016\n",
            "Train MAPE: 20.5775%, Val MAPE: 24.0957%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.001\n",
            "Initial loss: 1699.769593\n",
            "Final loss: 78.246230\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 73.6661, Val Loss: 111.5078\n",
            "Train MAPE: 19.9749%, Val MAPE: 24.8061%\n",
            "Results: Val Loss = 106.7641, Val MAPE = 24.2938%\n",
            "\n",
            "[8/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.01\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1647.304508\n",
            "Final loss: 92.568938\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 90.0313, Val Loss: 95.2380\n",
            "Train MAPE: 22.4341%, Val MAPE: 22.9692%\n",
            "\n",
            "Fold 2/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1708.998376\n",
            "Final loss: 93.610079\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 91.1381, Val Loss: 92.8350\n",
            "Train MAPE: 22.3867%, Val MAPE: 22.9669%\n",
            "\n",
            "Fold 3/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.01\n",
            "Initial loss: 1681.954670\n",
            "Final loss: 91.659451\n",
            "Optimization successful: False\n",
            "Number of iterations: 1000\n",
            "Train Loss: 88.6833, Val Loss: 96.7707\n",
            "Train MAPE: 22.1783%, Val MAPE: 23.1553%\n",
            "Results: Val Loss = 94.9479, Val MAPE = 23.0305%\n",
            "\n",
            "[9/24] Testing configuration:\n",
            "Layers: [128, 64] (hidden)\n",
            "Activation: tanh\n",
            "Lambda: 0.1\n",
            "\n",
            "Starting 3-fold cross-validation...\n",
            "\n",
            "Fold 1/3\n",
            "Training network with architecture: [32, 128, 64, 1]\n",
            "Activation: tanh, Lambda: 0.1\n",
            "Initial loss: 1681.707106\n"
          ]
        }
      ],
      "source": [
        "# Find best hyperparameters using cross-validation\n",
        "best_parameters, search_results = hyperparameter_search(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-8c4C5duvAB"
      },
      "source": [
        "### Training the final model with the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJsFXLw-u9rx"
      },
      "outputs": [],
      "source": [
        "# Train final model with best parameters\n",
        "final_weights, final_biases, optimization_result, initial_loss, final_loss = train_network(\n",
        "    X_train, y_train,\n",
        "    layer_sizes=best_parameters['layers'],\n",
        "    activation=best_parameters['activation'],\n",
        "    lambda_reg=best_parameters['lambda_reg'],\n",
        "    method='L-BFGS-B',\n",
        "    maxiter=1000\n",
        ")\n",
        "\n",
        "print(f\"\\nOptimization details:\")\n",
        "print(f\"Success: {optimization_result.success}\")\n",
        "print(f\"Message: {optimization_result.message}\")\n",
        "print(f\"Iterations: {optimization_result.nit}\")\n",
        "print(f\"Loss reduction: {initial_loss:.6f} -> {final_loss:.6f}\")\n",
        "\n",
        "# Make predictions on all datasets\n",
        "y_train_pred = predict(X_train, final_weights, final_biases, best_parameters['activation'])\n",
        "y_test_pred = predict(X_test, final_weights, final_biases, best_parameters['activation'])\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Absolute Percentage Error\n",
        "train_mape = MAPE(y_train, y_train_pred)\n",
        "test_mape = MAPE(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI8IfwTUw3SI"
      },
      "source": [
        "### Print Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_C8DE9BtrxZ"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nBest Network Configuration:\")\n",
        "print(f\"Architecture: {best_parameters['layers']}\")\n",
        "print(f\"Hidden layers: {best_parameters['layers'][1:-1]}\")\n",
        "print(f\"Activation function: {best_parameters['activation']}\")\n",
        "print(f\"Regularization (lambda): {best_parameters['lambda_reg']}\")\n",
        "print(f\"Total parameters: {sum(w.size + b.size for w, b in zip(final_weights, final_biases))}\")\n",
        "\n",
        "print(f\"\\nOptimization Results:\")\n",
        "print(f\"Method: L-BFGS-B\")\n",
        "print(f\"Max iterations: 1000\")\n",
        "print(f\"Convergence: {'Successful' if optimization_result.success else 'Failed'}\")\n",
        "print(f\"Iterations used: {optimization_result.nit}\")\n",
        "print(f\"Initial loss: {initial_loss:.6f}\")\n",
        "print(f\"Final loss: {final_loss:.6f}\")\n",
        "print(f\"Loss reduction: {((initial_loss - final_loss) / initial_loss * 100):.2f}%\")\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"Training MSE: {train_mse:.6f}\")\n",
        "print(f\"Test MSE: {test_mse:.6f}\")\n",
        "print(f\"Training MAPE: {train_mape:.4f}%\")\n",
        "print(f\"Test MAPE: {test_mape:.4f}%\")\n",
        "\n",
        "print(f\"\\nModel Insights:\")\n",
        "print(f\"Best performing activation: {best_parameters['activation']}\")\n",
        "print(f\"Optimal regularization strength: {best_parameters['lambda_reg']}\")\n",
        "print(f\"Network depth: {len(best_parameters['layers'])-1} layers\")\n",
        "print(f\"Network width: {max(best_parameters['layers'][1:-1])} neurons (max)\")\n",
        "\n",
        "\n",
        "# Save detailed results\n",
        "results_summary = {\n",
        "    'best_config': best_parameters,\n",
        "    'optimization_result': {\n",
        "        'success': optimization_result.success,\n",
        "        'message': optimization_result.message,\n",
        "        'iterations': optimization_result.nit,\n",
        "        'initial_loss': initial_loss,\n",
        "        'final_loss': final_loss\n",
        "    },\n",
        "    'performance_metrics': {\n",
        "        'train_mse': train_mse,\n",
        "        'test_mse': test_mse,\n",
        "        'train_mape': train_mape,\n",
        "        'test_mape': test_mape\n",
        "    },\n",
        "    'hyperparameter_search_results': search_results\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"results_summary.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results_summary,f)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
