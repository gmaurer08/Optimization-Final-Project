{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGoWHYiAMfG6"
      },
      "source": [
        "# Optimization Methods For Data Science\n",
        "## Final Project - Part 1: Multi-Layer-Perceptron\n",
        "\n",
        "Géraldine V. Maurer, Viktoriia Vlasenko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeCfItoVfj_m"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8fOoem53Hips"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcrOl70hfroh"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rQUTRpfjfhua"
      },
      "outputs": [],
      "source": [
        "# Gauss Kernel\n",
        "def gauss_kernel(x1, x2, gamma):\n",
        "    return np.exp(-gamma * np.linalg.norm(x1-x2)**2)\n",
        "\n",
        "# Polynomial Kernel\n",
        "def poly_kernel(x1, x2, gamma, p):\n",
        "    return (np.dot(x1, x2) + 1)**p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFd8X0WsfnDs"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_g087xD9fXQU",
        "outputId": "7ab97f91-172b-4955-96fa-0023707702ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3c1421e4-bef6-4089-9ff5-cb320dbbede7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_1</th>\n",
              "      <th>feat_2</th>\n",
              "      <th>feat_3</th>\n",
              "      <th>feat_4</th>\n",
              "      <th>feat_5</th>\n",
              "      <th>feat_6</th>\n",
              "      <th>feat_7</th>\n",
              "      <th>feat_8</th>\n",
              "      <th>feat_9</th>\n",
              "      <th>feat_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_24</th>\n",
              "      <th>feat_25</th>\n",
              "      <th>feat_26</th>\n",
              "      <th>feat_27</th>\n",
              "      <th>feat_28</th>\n",
              "      <th>feat_29</th>\n",
              "      <th>feat_30</th>\n",
              "      <th>feat_31</th>\n",
              "      <th>feat_32</th>\n",
              "      <th>gt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.900846</td>\n",
              "      <td>0.102587</td>\n",
              "      <td>-0.397814</td>\n",
              "      <td>0.112796</td>\n",
              "      <td>2.588096</td>\n",
              "      <td>-0.192754</td>\n",
              "      <td>-0.968311</td>\n",
              "      <td>-0.490886</td>\n",
              "      <td>-0.872099</td>\n",
              "      <td>-0.288411</td>\n",
              "      <td>...</td>\n",
              "      <td>2.541431</td>\n",
              "      <td>1.739102</td>\n",
              "      <td>0.166066</td>\n",
              "      <td>4.584869</td>\n",
              "      <td>-0.107031</td>\n",
              "      <td>-0.913990</td>\n",
              "      <td>-0.686416</td>\n",
              "      <td>-0.368085</td>\n",
              "      <td>-0.870545</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.838868</td>\n",
              "      <td>0.039976</td>\n",
              "      <td>-0.387101</td>\n",
              "      <td>0.055413</td>\n",
              "      <td>2.066874</td>\n",
              "      <td>-0.226948</td>\n",
              "      <td>-0.947416</td>\n",
              "      <td>-0.472817</td>\n",
              "      <td>-0.855387</td>\n",
              "      <td>-0.207101</td>\n",
              "      <td>...</td>\n",
              "      <td>1.991721</td>\n",
              "      <td>1.259745</td>\n",
              "      <td>0.065058</td>\n",
              "      <td>3.019790</td>\n",
              "      <td>-0.110633</td>\n",
              "      <td>-0.890023</td>\n",
              "      <td>-0.611625</td>\n",
              "      <td>-0.298235</td>\n",
              "      <td>-0.855208</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.814961</td>\n",
              "      <td>-0.010184</td>\n",
              "      <td>-0.397147</td>\n",
              "      <td>0.092713</td>\n",
              "      <td>1.897454</td>\n",
              "      <td>-0.269387</td>\n",
              "      <td>-0.945285</td>\n",
              "      <td>-0.449579</td>\n",
              "      <td>-0.849705</td>\n",
              "      <td>-0.151179</td>\n",
              "      <td>...</td>\n",
              "      <td>1.822978</td>\n",
              "      <td>1.105511</td>\n",
              "      <td>0.065353</td>\n",
              "      <td>2.500681</td>\n",
              "      <td>-0.052730</td>\n",
              "      <td>-0.885691</td>\n",
              "      <td>-0.583346</td>\n",
              "      <td>-0.218140</td>\n",
              "      <td>-0.856456</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.110470</td>\n",
              "      <td>0.027849</td>\n",
              "      <td>-0.044310</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>0.177831</td>\n",
              "      <td>-0.232092</td>\n",
              "      <td>-0.562700</td>\n",
              "      <td>-0.400713</td>\n",
              "      <td>-0.552356</td>\n",
              "      <td>0.037349</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.098367</td>\n",
              "      <td>-0.370318</td>\n",
              "      <td>-0.123008</td>\n",
              "      <td>-0.861314</td>\n",
              "      <td>0.106840</td>\n",
              "      <td>-0.483669</td>\n",
              "      <td>-0.224164</td>\n",
              "      <td>0.147321</td>\n",
              "      <td>-0.615051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.626313</td>\n",
              "      <td>-0.091985</td>\n",
              "      <td>-0.373756</td>\n",
              "      <td>-0.005083</td>\n",
              "      <td>1.172486</td>\n",
              "      <td>-0.314868</td>\n",
              "      <td>-0.885046</td>\n",
              "      <td>-0.412587</td>\n",
              "      <td>-0.818729</td>\n",
              "      <td>-0.012022</td>\n",
              "      <td>...</td>\n",
              "      <td>1.030348</td>\n",
              "      <td>0.421886</td>\n",
              "      <td>-0.068029</td>\n",
              "      <td>0.258984</td>\n",
              "      <td>-0.057158</td>\n",
              "      <td>-0.834079</td>\n",
              "      <td>-0.441066</td>\n",
              "      <td>-0.099874</td>\n",
              "      <td>-0.829539</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1421e4-bef6-4089-9ff5-cb320dbbede7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c1421e4-bef6-4089-9ff5-cb320dbbede7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c1421e4-bef6-4089-9ff5-cb320dbbede7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a30e9c95-681b-4ef0-a495-1445b2e4db1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a30e9c95-681b-4ef0-a495-1445b2e4db1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a30e9c95-681b-4ef0-a495-1445b2e4db1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
              "0 -0.900846  0.102587 -0.397814  0.112796  2.588096 -0.192754 -0.968311   \n",
              "1 -0.838868  0.039976 -0.387101  0.055413  2.066874 -0.226948 -0.947416   \n",
              "2 -0.814961 -0.010184 -0.397147  0.092713  1.897454 -0.269387 -0.945285   \n",
              "3 -0.110470  0.027849 -0.044310 -0.005343  0.177831 -0.232092 -0.562700   \n",
              "4 -0.626313 -0.091985 -0.373756 -0.005083  1.172486 -0.314868 -0.885046   \n",
              "\n",
              "     feat_8    feat_9   feat_10  ...   feat_24   feat_25   feat_26   feat_27  \\\n",
              "0 -0.490886 -0.872099 -0.288411  ...  2.541431  1.739102  0.166066  4.584869   \n",
              "1 -0.472817 -0.855387 -0.207101  ...  1.991721  1.259745  0.065058  3.019790   \n",
              "2 -0.449579 -0.849705 -0.151179  ...  1.822978  1.105511  0.065353  2.500681   \n",
              "3 -0.400713 -0.552356  0.037349  ... -0.098367 -0.370318 -0.123008 -0.861314   \n",
              "4 -0.412587 -0.818729 -0.012022  ...  1.030348  0.421886 -0.068029  0.258984   \n",
              "\n",
              "    feat_28   feat_29   feat_30   feat_31   feat_32  gt  \n",
              "0 -0.107031 -0.913990 -0.686416 -0.368085 -0.870545   0  \n",
              "1 -0.110633 -0.890023 -0.611625 -0.298235 -0.855208   0  \n",
              "2 -0.052730 -0.885691 -0.583346 -0.218140 -0.856456   0  \n",
              "3  0.106840 -0.483669 -0.224164  0.147321 -0.615051   0  \n",
              "4 -0.057158 -0.834079 -0.441066 -0.099874 -0.829539   0  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gmaurer08/Optimization-Final-Project/refs/heads/main/GENDER_CLASSIFICATION.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HenWiNLfp9k"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7oAKtJ8tfUyv"
      },
      "outputs": [],
      "source": [
        "# Split into x and y\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values\n",
        "\n",
        "# Standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)\n",
        "\n",
        "# Split into test and train set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghz3-7owHdLD"
      },
      "outputs": [],
      "source": [
        "# ----- SVM Dual with CVXOPT + k-fold CV (Question 2) -----\n",
        "\n",
        "import numpy as np\n",
        "from cvxopt import matrix, solvers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Keeping CVXOPT quiet so the notebook output stays clean; solver params remain DEFAULT as per assignment\n",
        "solvers.options['show_progress'] = False   # Optimization routine: CVXOPT 'qp' (settings: DEFAULT)\n",
        "\n",
        "# quick note: the dual SVM expects labels in {-1,+1}, while your dataset uses {0,1}\n",
        "# We map once here for the final train/test training stage; CV does its own mapping inside\n",
        "y_train_svm = np.where(y_train==0, -1.0, 1.0)\n",
        "y_test_svm  = np.where(y_test==0, -1.0, 1.0)\n",
        "\n",
        "# helper kernels (vectorized) to avoid Python loops, which would be slow\n",
        "def rbf_kernel_matrix(X1, X2, gamma: float):\n",
        "    # Computes pairwise squared Euclidean distances efficiently using ||a-b||^2=||a||^2+||b||^2-2a^Tb\n",
        "    X1_sq = np.sum(X1**2, axis=1)[:, None]   # each row's squared norm\n",
        "    X2_sq = np.sum(X2**2, axis=1)[None, :]   # each row's squared norm (broadcast shape)\n",
        "    # Capitalized: this constructs the full pairwise squared distance matrix\n",
        "    sq_dists = X1_sq+X2_sq-2*(X1 @ X2.T)\n",
        "    # returns K_ij=exp(-gamma*||xi-xj||^2)\n",
        "    return np.exp(-gamma*sq_dists)\n",
        "\n",
        "def poly_kernel_matrix(X1, X2, p: int):\n",
        "    # a classic in SVMs: adds a bias 1.0 then raises to power p\n",
        "    return (X1 @ X2.T+1.0)**p\n",
        "\n",
        "def make_kernel_mats(Xtr, Xte, kernel_name: str, **kparams):\n",
        "    # chooses the right kernel and builds train/train and train/test Gram blocks\n",
        "    if kernel_name=='rbf':\n",
        "        K_tr = rbf_kernel_matrix(Xtr, Xtr, gamma=kparams['gamma'])\n",
        "        K_te = rbf_kernel_matrix(Xtr, Xte, gamma=kparams['gamma'])\n",
        "    elif kernel_name=='poly':\n",
        "        K_tr = poly_kernel_matrix(Xtr, Xtr, p=kparams['p'])\n",
        "        K_te = poly_kernel_matrix(Xtr, Xte, p=kparams['p'])\n",
        "    else:\n",
        "        # Little guardrail: fail fast if kernel_name is wrong\n",
        "        raise ValueError(\"kernel_name must be 'rbf' or 'poly'\")\n",
        "    # tiny jitter for numerical stability (helps positive definiteness in practice)\n",
        "    K_tr = K_tr+1e-8*np.eye(K_tr.shape[0])\n",
        "    return K_tr, K_te\n",
        "\n",
        "# now we solve the dual QP:\n",
        "#    maximize  1^T a - 1/2 a^T (Y Y^T .* K) a\n",
        "#    subject to 0<=a_i<=C and y^T a=0\n",
        "# cvxopt solves a MIN problem, so we flip signs accordingly\n",
        "def solve_svm_dual(K_tr: np.ndarray, ytr: np.ndarray, C: float):\n",
        "    n = ytr.shape[0]  # number of training points in this fold\n",
        "    Y = ytr.reshape(-1, 1)  # column vector\n",
        "    P = (Y @ Y.T)*K_tr      # This is (y y^T)⊙K (elementwise via broadcasted product)\n",
        "    # cvxopt form: min (1/2)a^T P a + q^T a, with G a<=h, A a=b\n",
        "    P_cvx = matrix(P, tc='d')                      # Positive semidefinite matrix for QP\n",
        "    q_cvx = matrix(-np.ones(n), tc='d')            # q=-1 -> objective matches the negated dual\n",
        "    # box constraints 0<=a<=C encoded as two stacks: -I a<=0 and I a<=C\n",
        "    G = np.vstack([-np.eye(n), np.eye(n)])         # Concatenates the two inequality blocks\n",
        "    h = np.hstack([np.zeros(n), np.full(n, C)])    # Corresponding right-hand sides\n",
        "    G_cvx = matrix(G, tc='d')\n",
        "    h_cvx = matrix(h, tc='d')\n",
        "    # equality constraint enforces y^T a=0 (feasibility on the margin balance)\n",
        "    A_cvx = matrix(ytr.reshape(1, -1), tc='d')\n",
        "    b_cvx = matrix(0.0)\n",
        "    # important: we keep default tolerances/parameters (as requested)\n",
        "    sol = solvers.qp(P_cvx, q_cvx, G_cvx, h_cvx, A_cvx, b_cvx)\n",
        "    alphas = np.array(sol['x']).ravel()            # The dual variables a_i\n",
        "    return alphas, sol, P                          # returning P helps evaluate the dual objective if needed\n",
        "\n",
        "def compute_b(alphas: np.ndarray, ytr: np.ndarray, K_tr: np.ndarray, C: float):\n",
        "    # finds the bias b by averaging across margin SVs (0<a_i<C), fallback to all SVs if none are free\n",
        "    eps = 1e-6\n",
        "    sv = (alphas>eps)                               # support vectors (nonzero alphas)\n",
        "    sv_margin = (alphas>eps) & (alphas<C-eps)       # free SVs inside the box\n",
        "    idx = np.where(sv_margin)[0]\n",
        "    if idx.size==0:                                 # sometimes all SVs hit the box; average over them instead\n",
        "        idx = np.where(sv)[0]\n",
        "    # b = y_i - sum_j a_j y_j K_ji, averaged over chosen SVs\n",
        "    b_vals = ytr[idx]-(alphas*ytr) @ K_tr[:, idx]\n",
        "    return float(np.mean(b_vals)), sv               # returns mean bias and the SV mask for stats\n",
        "\n",
        "def decision_function(alphas, ytr, K_te, b):\n",
        "    # computes f(x)=sum_i a_i y_i K(x_i,x)+b for a batch via Gram block K_te\n",
        "    return (alphas*ytr) @ K_te+b\n",
        "\n",
        "def accuracy_from_scores(scores, y_true_binary01):\n",
        "    # small bridge: scores>=0 -> class 1 else 0 (consistent with our {-1,+1} mapping)\n",
        "    y_pred = (scores>=0).astype(int)\n",
        "    return float(np.mean(y_pred==y_true_binary01))\n",
        "\n",
        "# cross-validation utilities\n",
        "from itertools import product\n",
        "\n",
        "def grid_from_dict(d):\n",
        "    # expands a dict of lists into a cartesian product of param dicts\n",
        "    keys = list(d.keys())\n",
        "    for values in product(*[d[k] for k in keys]):   # note: star here is argument unpacking, not multiplication\n",
        "        yield dict(zip(keys, values))\n",
        "\n",
        "def cross_validate_svm(X, y_binary01, kernel_name: str, param_grid: dict, k: int=5):\n",
        "    # Stratified splits preserve class balance; we remap labels to {-1,+1} per fold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    best_params, best_mean = None, -np.inf\n",
        "    history = []  # we’ll keep (params, mean_acc, fold_accs) to report in the write-up if needed\n",
        "    for params in grid_from_dict(param_grid):\n",
        "        # lowercase: collect each fold's validation accuracy\n",
        "        fold_accs = []\n",
        "        for tr_idx, va_idx in skf.split(X, y_binary01):\n",
        "            Xtr, Xva = X[tr_idx], X[va_idx]\n",
        "            ytr01, yva01 = y_binary01[tr_idx], y_binary01[va_idx]\n",
        "            ytr = np.where(ytr01==0, -1.0, 1.0)\n",
        "            # Build Gram matrices for this fold; caching could speed up further if needed\n",
        "            K_tr, K_va = make_kernel_mats(Xtr, Xva, kernel_name, **params)\n",
        "            # Solve the dual with CVXOPT\n",
        "            alphas, sol, P = solve_svm_dual(K_tr, ytr, C=params['C'])\n",
        "            # estimate bias using margin SVs, then evaluate on validation\n",
        "            b, _ = compute_b(alphas, ytr, K_tr, C=params['C'])\n",
        "            scores_va = decision_function(alphas, ytr, K_va, b)\n",
        "            acc_va = accuracy_from_scores(scores_va, yva01)\n",
        "            fold_accs.append(acc_va)\n",
        "        mean_acc = float(np.mean(fold_accs))\n",
        "        history.append((params.copy(), mean_acc, fold_accs.copy()))\n",
        "        # Capitalized: track the best hyperparameters by mean validation accuracy\n",
        "        if mean_acc>best_mean:\n",
        "            best_mean, best_params = mean_acc, params.copy()\n",
        "    return best_params, best_mean, history\n",
        "\n",
        "# choose kernel & hyperparameter grid; this is a sensible baseline\n",
        "KERNEL = 'rbf'  # 'rbf' or 'poly'\n",
        "\n",
        "if KERNEL=='rbf':\n",
        "    # gamma sweeps a few orders; C explores under/over-regularization\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [0.01, 0.1, 1.0]\n",
        "    }\n",
        "elif KERNEL=='poly':\n",
        "    # polynomial degree p controls model capacity; often p=2..4 is plenty\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'p': [2, 3, 4]\n",
        "    }\n",
        "else:\n",
        "    # friendly failure if someone mistypes the kernel name\n",
        "    raise ValueError(\"KERNEL must be 'rbf' or 'poly'\")\n",
        "\n",
        "# run cross-validation to pick (C, kernel hyperparam)\n",
        "best_params, val_best_mean, cv_history = cross_validate_svm(\n",
        "    x_train, (y_train>0).astype(int), KERNEL, param_grid, k=5\n",
        ")\n",
        "\n",
        "print(f\"[CV] Kernel = {KERNEL} | Best params = {best_params} | Mean 5-fold val acc = {val_best_mean:.4f}\")\n",
        "\n",
        "# Train FINAL model on the whole training split using the best hyperparameters from CV\n",
        "K_tr, K_te = make_kernel_mats(x_train, x_test, KERNEL, **best_params)\n",
        "alphas, sol, P = solve_svm_dual(K_tr, y_train_svm, C=best_params['C'])\n",
        "b, sv_mask = compute_b(alphas, y_train_svm, K_tr, C=best_params['C'])\n",
        "\n",
        "# compute accuracies to report (train/test)\n",
        "scores_tr = decision_function(alphas, y_train_svm, K_tr, b)\n",
        "scores_te = decision_function(alphas, y_train_svm, K_te, b)\n",
        "train_acc = accuracy_from_scores(scores_tr, (y_train>0).astype(int))\n",
        "test_acc  = accuracy_from_scores(scores_te,  (y_test>0).astype(int))\n",
        "\n",
        "# optimization diagnostics for the report:\n",
        "# cvxopt solves min g(a)=1/2 a^T P a - 1^T a ; the dual objective is f(a)=-g(a)\n",
        "a = alphas\n",
        "primal_obj_g = float(sol['primal objective'])    # value minimized by cvxopt\n",
        "final_dual_obj = -primal_obj_g                   # flip sign to get maximized dual\n",
        "initial_dual_obj = 0.0                           # at a=0 the dual is 0\n",
        "iterations = int(sol['iterations'])\n",
        "num_sv = int(np.sum(sv_mask))\n",
        "\n",
        "print(\"\\n--- RESULTS (Question 2) ---\")\n",
        "print(f\"Kernel: {KERNEL}\")\n",
        "print(f\"Best hyperparameters (via 5-fold CV): {best_params}\")\n",
        "print(f\"Validation (mean over folds): {val_best_mean:.4f}\")\n",
        "print(f\"Train accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test  accuracy: {test_acc:.4f}\")\n",
        "print(f\"Support vectors: {num_sv} / {len(y_train_svm)}\")\n",
        "\n",
        "print(\"\\nOptimization performance (final training run):\")\n",
        "print(f\"  Optimization routine: CVXOPT 'qp' (parameters: DEFAULT)\")\n",
        "print(f\"  Dual objective: initial = {initial_dual_obj:.6f}, final = {final_dual_obj:.6f}\")\n",
        "print(f\"  Iterations: {iterations}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
