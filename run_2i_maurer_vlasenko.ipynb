{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGoWHYiAMfG6"
      },
      "source": [
        "# Optimization Methods For Data Science\n",
        "## Final Project - Part 1: Multi-Layer-Perceptron\n",
        "\n",
        "Géraldine V. Maurer, Viktoriia Vlasenko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeCfItoVfj_m"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8fOoem53Hips"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from cvxopt import matrix, solvers\n",
        "from itertools import product\n",
        "import time\n",
        "from functions_2j_maurer_vlasenko import *\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED=123\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"]=str(SEED)\n",
        "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"]=\"1\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"]=\"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFd8X0WsfnDs"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_g087xD9fXQU",
        "outputId": "7ab97f91-172b-4955-96fa-0023707702ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_1</th>\n",
              "      <th>feat_2</th>\n",
              "      <th>feat_3</th>\n",
              "      <th>feat_4</th>\n",
              "      <th>feat_5</th>\n",
              "      <th>feat_6</th>\n",
              "      <th>feat_7</th>\n",
              "      <th>feat_8</th>\n",
              "      <th>feat_9</th>\n",
              "      <th>feat_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_24</th>\n",
              "      <th>feat_25</th>\n",
              "      <th>feat_26</th>\n",
              "      <th>feat_27</th>\n",
              "      <th>feat_28</th>\n",
              "      <th>feat_29</th>\n",
              "      <th>feat_30</th>\n",
              "      <th>feat_31</th>\n",
              "      <th>feat_32</th>\n",
              "      <th>gt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.900846</td>\n",
              "      <td>0.102587</td>\n",
              "      <td>-0.397814</td>\n",
              "      <td>0.112796</td>\n",
              "      <td>2.588096</td>\n",
              "      <td>-0.192754</td>\n",
              "      <td>-0.968311</td>\n",
              "      <td>-0.490886</td>\n",
              "      <td>-0.872099</td>\n",
              "      <td>-0.288411</td>\n",
              "      <td>...</td>\n",
              "      <td>2.541431</td>\n",
              "      <td>1.739102</td>\n",
              "      <td>0.166066</td>\n",
              "      <td>4.584869</td>\n",
              "      <td>-0.107031</td>\n",
              "      <td>-0.913990</td>\n",
              "      <td>-0.686416</td>\n",
              "      <td>-0.368085</td>\n",
              "      <td>-0.870545</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.838868</td>\n",
              "      <td>0.039976</td>\n",
              "      <td>-0.387101</td>\n",
              "      <td>0.055413</td>\n",
              "      <td>2.066874</td>\n",
              "      <td>-0.226948</td>\n",
              "      <td>-0.947416</td>\n",
              "      <td>-0.472817</td>\n",
              "      <td>-0.855387</td>\n",
              "      <td>-0.207101</td>\n",
              "      <td>...</td>\n",
              "      <td>1.991721</td>\n",
              "      <td>1.259745</td>\n",
              "      <td>0.065058</td>\n",
              "      <td>3.019790</td>\n",
              "      <td>-0.110633</td>\n",
              "      <td>-0.890023</td>\n",
              "      <td>-0.611625</td>\n",
              "      <td>-0.298235</td>\n",
              "      <td>-0.855208</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.814961</td>\n",
              "      <td>-0.010184</td>\n",
              "      <td>-0.397147</td>\n",
              "      <td>0.092713</td>\n",
              "      <td>1.897454</td>\n",
              "      <td>-0.269387</td>\n",
              "      <td>-0.945285</td>\n",
              "      <td>-0.449579</td>\n",
              "      <td>-0.849705</td>\n",
              "      <td>-0.151179</td>\n",
              "      <td>...</td>\n",
              "      <td>1.822978</td>\n",
              "      <td>1.105511</td>\n",
              "      <td>0.065353</td>\n",
              "      <td>2.500681</td>\n",
              "      <td>-0.052730</td>\n",
              "      <td>-0.885691</td>\n",
              "      <td>-0.583346</td>\n",
              "      <td>-0.218140</td>\n",
              "      <td>-0.856456</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.110470</td>\n",
              "      <td>0.027849</td>\n",
              "      <td>-0.044310</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>0.177831</td>\n",
              "      <td>-0.232092</td>\n",
              "      <td>-0.562700</td>\n",
              "      <td>-0.400713</td>\n",
              "      <td>-0.552356</td>\n",
              "      <td>0.037349</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.098367</td>\n",
              "      <td>-0.370318</td>\n",
              "      <td>-0.123008</td>\n",
              "      <td>-0.861314</td>\n",
              "      <td>0.106840</td>\n",
              "      <td>-0.483669</td>\n",
              "      <td>-0.224164</td>\n",
              "      <td>0.147321</td>\n",
              "      <td>-0.615051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.626313</td>\n",
              "      <td>-0.091985</td>\n",
              "      <td>-0.373756</td>\n",
              "      <td>-0.005083</td>\n",
              "      <td>1.172486</td>\n",
              "      <td>-0.314868</td>\n",
              "      <td>-0.885046</td>\n",
              "      <td>-0.412587</td>\n",
              "      <td>-0.818729</td>\n",
              "      <td>-0.012022</td>\n",
              "      <td>...</td>\n",
              "      <td>1.030348</td>\n",
              "      <td>0.421886</td>\n",
              "      <td>-0.068029</td>\n",
              "      <td>0.258984</td>\n",
              "      <td>-0.057158</td>\n",
              "      <td>-0.834079</td>\n",
              "      <td>-0.441066</td>\n",
              "      <td>-0.099874</td>\n",
              "      <td>-0.829539</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
              "0 -0.900846  0.102587 -0.397814  0.112796  2.588096 -0.192754 -0.968311   \n",
              "1 -0.838868  0.039976 -0.387101  0.055413  2.066874 -0.226948 -0.947416   \n",
              "2 -0.814961 -0.010184 -0.397147  0.092713  1.897454 -0.269387 -0.945285   \n",
              "3 -0.110470  0.027849 -0.044310 -0.005343  0.177831 -0.232092 -0.562700   \n",
              "4 -0.626313 -0.091985 -0.373756 -0.005083  1.172486 -0.314868 -0.885046   \n",
              "\n",
              "     feat_8    feat_9   feat_10  ...   feat_24   feat_25   feat_26   feat_27  \\\n",
              "0 -0.490886 -0.872099 -0.288411  ...  2.541431  1.739102  0.166066  4.584869   \n",
              "1 -0.472817 -0.855387 -0.207101  ...  1.991721  1.259745  0.065058  3.019790   \n",
              "2 -0.449579 -0.849705 -0.151179  ...  1.822978  1.105511  0.065353  2.500681   \n",
              "3 -0.400713 -0.552356  0.037349  ... -0.098367 -0.370318 -0.123008 -0.861314   \n",
              "4 -0.412587 -0.818729 -0.012022  ...  1.030348  0.421886 -0.068029  0.258984   \n",
              "\n",
              "    feat_28   feat_29   feat_30   feat_31   feat_32  gt  \n",
              "0 -0.107031 -0.913990 -0.686416 -0.368085 -0.870545   0  \n",
              "1 -0.110633 -0.890023 -0.611625 -0.298235 -0.855208   0  \n",
              "2 -0.052730 -0.885691 -0.583346 -0.218140 -0.856456   0  \n",
              "3  0.106840 -0.483669 -0.224164  0.147321 -0.615051   0  \n",
              "4 -0.057158 -0.834079 -0.441066 -0.099874 -0.829539   0  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gmaurer08/Optimization-Final-Project/refs/heads/main/GENDER_CLASSIFICATION.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2: SVM Dual with CVXOPT + k-fold CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HenWiNLfp9k"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7oAKtJ8tfUyv"
      },
      "outputs": [],
      "source": [
        "# Split into x and y\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values\n",
        "\n",
        "# Standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)\n",
        "\n",
        "# Split into test and train set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2)\n",
        "\n",
        "# Suppress progress outputs\n",
        "solvers.options['show_progress'] = False  # Optimization routine: CVXOPT 'qp' (default settings)\n",
        "\n",
        "# The dual SVM expects labels in {-1,+1}, while our dataset uses {0,1}\n",
        "# We map once here for the final training stage, CV does its own mapping inside\n",
        "y_train_svm = np.where(y_train==0,-1.0,1.0)\n",
        "y_test_svm  = np.where(y_test==0,-1.0,1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose Kernel and set parameter grids for Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# kernel & hyperparameter grid\n",
        "KERNEL = 'rbf'  # rbf or poly\n",
        "\n",
        "if KERNEL=='rbf':\n",
        "    # parameter grid for hyperparameter optimization\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [0.01, 0.1, 1.0]\n",
        "    }\n",
        "elif KERNEL=='poly':\n",
        "    # polynomial degree p controls model capacity; often p=2..4 is plenty\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'p': [2, 3, 4]\n",
        "    }\n",
        "else:\n",
        "    # friendly failure if someone mistypes the kernel name\n",
        "    raise ValueError(\"KERNEL must be 'rbf' or 'poly'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run Cross-Validation with k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel = rbf\n",
            "Best parameters = {'C': 1, 'gamma': 0.1}\n",
            "Mean 5-fold val acc = 0.9225\n"
          ]
        }
      ],
      "source": [
        "# Run cross-validation to pick (C, kernel hyperparam)\n",
        "best_params, val_best_mean, cv_history = cross_validate_svm(\n",
        "    x_train, (y_train>0).astype(int), KERNEL, param_grid, k=5, seed=SEED\n",
        ")\n",
        "\n",
        "print(f\"Kernel = {KERNEL}\")\n",
        "print(f\"Best parameters = {best_params}\")\n",
        "print(f\"Mean 5-fold val acc = {val_best_mean:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: rbf\n",
            "Hyperparameters: {'C': 1, 'gamma': 0.1}\n",
            "\n",
            "Classification accuracy (train): 0.9225\n",
            "Classification accuracy (test):  0.9000\n",
            "\n",
            "Confusion matrix (train) [rows=true 0/1, cols=pred 0/1]:\n",
            "[[366  33]\n",
            " [ 29 372]]\n",
            "Confusion matrix (test)  [rows=true 0/1, cols=pred 0/1]:\n",
            "[[90 11]\n",
            " [ 9 90]]\n",
            "\n",
            "Optimization time: 1.7618 s\n",
            "Optimization iterations: 14\n",
            "Final dual SVM objective: 132.722617\n"
          ]
        }
      ],
      "source": [
        "# Train FINAL model on the whole training split using the best hyperparameters from CV\n",
        "\n",
        "# Make the kernel matrices\n",
        "K_train, K_test = make_kernel_matrices(x_train, x_test, KERNEL, **best_params)\n",
        "\n",
        "# Time the optimization\n",
        "start_time = time.time()\n",
        "\n",
        "# Solve SVM dual problem\n",
        "alphas, sol, Q = solve_svm_dual(K_train, y_train_svm, C=best_params['C'])\n",
        "\n",
        "# Measure time difference\n",
        "end_time = time.time()\n",
        "optimization_time = end_time - start_time\n",
        "\n",
        "# Compute Bias\n",
        "b, sv_mask = compute_b(alphas, y_train_svm, K_train, C=best_params['C'])\n",
        "\n",
        "# Scores\n",
        "scores_train = decision_function(alphas, y_train_svm, K_train, b)\n",
        "scores_test = decision_function(alphas, y_train_svm, K_test, b)\n",
        "\n",
        "# Accuracies (classification rates)\n",
        "ytrue_train01 = (y_train>0).astype(int)\n",
        "ytrue_test01 = (y_test>0).astype(int)\n",
        "train_acc = accuracy_from_scores(scores_train, ytrue_train01)\n",
        "test_acc = accuracy_from_scores(scores_test, ytrue_test01)\n",
        "\n",
        "# Confusion matrices\n",
        "ypred_train01 = (scores_train>=0).astype(int)\n",
        "ypred_test01 = (scores_test>=0).astype(int)\n",
        "cm_train = confusion_matrix(ytrue_train01, ypred_train01, labels=[0,1])\n",
        "cm_test = confusion_matrix(ytrue_test01, ypred_test01, labels=[0,1])\n",
        "\n",
        "# Optimization diagnostics\n",
        "# cvxopt solves min g(a)=1/2 a^T Q a - 1^T a ; the dual objective is f(a)=-g(a)\n",
        "a = alphas\n",
        "primal_obj_g = float(sol['primal objective']) # value minimized by cvxopt\n",
        "final_dual_obj = -primal_obj_g # flip sign to get maximized dual\n",
        "initial_dual_obj = 0.0 # at a=0 the dual is 0\n",
        "iterations = int(sol['iterations'])\n",
        "num_sv = int(np.sum(sv_mask))\n",
        "\n",
        "print(f\"Kernel: {KERNEL}\")\n",
        "print(f\"Hyperparameters: {best_params}\")  # setting values of the hyperparameters\n",
        "\n",
        "print(f\"\\nClassification accuracy (train): {train_acc:.4f}\")\n",
        "print(f\"Classification accuracy (test):  {test_acc:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion matrix (train) [rows=true 0/1, cols=pred 0/1]:\")\n",
        "print(cm_train)\n",
        "print(\"Confusion matrix (test)  [rows=true 0/1, cols=pred 0/1]:\")\n",
        "print(cm_test)\n",
        "\n",
        "print(f\"\\nOptimization time: {optimization_time:.4f} s\")\n",
        "print(f\"Optimization iterations: {iterations}\")\n",
        "print(f\"Final dual SVM objective: {final_dual_obj:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3: MVP Decomposition (q=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel: rbf\n",
            "Hyperparameters: {'C': 1, 'gamma': 0.1}\n",
            "Train accuracy: 0.9225\n",
            "Test  accuracy: 0.9000\n",
            "Support vectors: 163 / 800\n",
            "\n",
            "Optimization performance (MVP):\n",
            "  Initial dual objective: 0.000000\n",
            "  Final   dual objective: 132.722442\n",
            "  Iterations (pair updates): 2920\n",
            "  KKT violation at stop (b_low-b_up): 8.801e-04\n"
          ]
        }
      ],
      "source": [
        "# ----- MVP Decomposition (q=2) — Question 3 -----\n",
        "# this implements a working-set method that picks the Most Violating Pair (MVP)\n",
        "# and solves the 2-variable subproblem analytically each iteration.\n",
        "\n",
        "def mvp_train(K: np.ndarray, y: np.ndarray, C: float, tol: float=1e-3, max_iter: int=200000):\n",
        "    \"\"\"\n",
        "    Minimizes the dual objective g(a)=0.5*a^T*Q*a-1^T*a with Q=(y y^T) @ K\n",
        "    subject to 0<=a_i<=C and y^T a=0 using q=2 MVP updates.\n",
        "\n",
        "    returns: alphas, stats dict with iterations, final dual obj (and the KKT gap)\n",
        "    \"\"\"\n",
        "    n = y.shape[0]\n",
        "    a = np.zeros(n) # start at 0 (feasible: y^T a=0)\n",
        "    # gradient of g(a)= Q a - 1; at a=0 this is -1\n",
        "    g = -np.ones(n)\n",
        "\n",
        "    # for objective tracking: start at g(0)=0; accumulate exact per-step changes\n",
        "    primal_obj_g = 0.0\n",
        "\n",
        "    # small helpers to build the index sets used by MVP\n",
        "    def I_up(a, y):\n",
        "        # KKT says if y_i==+1 then a_i<C can move up; if y_i==-1 then a_i>0 can move up\n",
        "        return ((y==1)&(a<C)) | ((y==-1)&(a>0))\n",
        "    def I_low(a, y):\n",
        "        # and the complementary set that can move down (in projected sense)\n",
        "        return ((y==1)&(a>0)) | ((y==-1)&(a<C))\n",
        "\n",
        "    it = 0\n",
        "    while it<max_iter:\n",
        "        yg = y*g\n",
        "\n",
        "        mask_up = I_up(a, y)\n",
        "        mask_low = I_low(a, y)\n",
        "\n",
        "        if not np.any(mask_up) or not np.any(mask_low):\n",
        "            # weird corner case: nothing movable; treat as converged\n",
        "            break\n",
        "\n",
        "        # MVP: pick i with smallest y_i*g_i (most negative), and j with largest y_j*g_j\n",
        "        i = np.argmin(np.where(mask_up, yg, np.inf))\n",
        "        j = np.argmax(np.where(mask_low, yg, -np.inf))\n",
        "\n",
        "        b_up = yg[i]\n",
        "        b_low = yg[j]\n",
        "        # stopping rule (Keerthi et al.): gap<=tol means approximate KKT satisfied\n",
        "        gap = b_low-b_up\n",
        "        if gap<=tol:\n",
        "            break\n",
        "\n",
        "        # Analytic 2-variable step:\n",
        "        s = y[i]*y[j]              # s in {+1,-1}\n",
        "        d_i = 1.0\n",
        "        d_j = -s\n",
        "        # directional derivative and curvature along feasible line\n",
        "        dTg = g[i]-s*g[j]          # equals derivative of g along direction\n",
        "        den = K[i,i]+K[j,j]-2.0*K[i,j]   # curvature: d^T*Q*d (simplifies nicely)\n",
        "\n",
        "        # Feasible box bounds for delta depending on s\n",
        "        if s==1:\n",
        "            L = max(-a[i], a[j]-C)\n",
        "            U = min(C-a[i], a[j])\n",
        "        else:  # s==-1\n",
        "            L = max(-a[i], -a[j])\n",
        "            U = min(C-a[i], C-a[j])\n",
        "\n",
        "        # proposed unconstrained step then clipped to [L,U]; if den<=0, pick bound for descent\n",
        "        if den>1e-12:\n",
        "            delta = -dTg/den\n",
        "            # lowercase: clip to the feasible interval\n",
        "            if delta<U:\n",
        "                delta = delta\n",
        "            else:\n",
        "                delta = U\n",
        "            if delta>L:\n",
        "                delta = delta\n",
        "            else:\n",
        "                delta = L\n",
        "        else:\n",
        "            # non-positive curvature: step to the bound that most decreases g\n",
        "            delta = L if dTg>0 else U\n",
        "\n",
        "        if abs(delta)<=1e-20:\n",
        "            # No meaningful progress, consider converged\n",
        "            break\n",
        "\n",
        "        # Update alphas (feasible move preserves y^T a=0 by construction)\n",
        "        a_i_old, a_j_old = a[i], a[j]\n",
        "        a[i] = a[i]+delta\n",
        "        a[j] = a[j]-s*delta\n",
        "\n",
        "        # Gradient update: g <- g + Q[:,i]*delta_i + Q[:,j]*delta_j\n",
        "        # Q[:,i] = y*y[i]*K[:,i]; delta_j=-s*delta\n",
        "        g = g+(y*y[i])*K[:, i]*delta+(y*y[j])*K[:, j]*(-s*delta)\n",
        "\n",
        "        # Exact objective change using quadratic model at old g\n",
        "        # Δg = dTg*delta + 0.5*den*delta^2\n",
        "        primal_obj_g = primal_obj_g+dTg*delta+0.5*den*(delta**2)\n",
        "\n",
        "        it+=1\n",
        "\n",
        "    stats = {\n",
        "        'iterations': it,\n",
        "        'kkt_gap': float(max(0.0, gap)) if 'gap' in locals() else float('nan'),\n",
        "        'primal_obj_g': float(primal_obj_g),   # minimized objective value g(a)\n",
        "        'dual_obj': float(-primal_obj_g)       # dual objective f(a)=-g(a)\n",
        "    }\n",
        "    return a, stats\n",
        "\n",
        "# Train & Evaluate MVP using the best hyperparams from Q2 (or set your own)\n",
        "\n",
        "# Use the same kernel/hyperparams chosen in Question 2; if not defined, set a default.\n",
        "try:\n",
        "    kernel_for_q3 = KERNEL\n",
        "    best_for_q3 = dict(best_params)\n",
        "except NameError:\n",
        "    kernel_for_q3 = 'rbf'\n",
        "    best_for_q3 = {'C': 1.0, 'gamma': 0.1}\n",
        "\n",
        "# labels in {-1,+1} for the dual\n",
        "ytr_svm = np.where(y_train==0, -1.0, 1.0)\n",
        "yte_svm = np.where(y_test==0, -1.0, 1.0)\n",
        "\n",
        "# Build kernel matrices\n",
        "K_train_q3, K_test_q3 = make_kernel_matrices(x_train, x_test, kernel_for_q3, **best_for_q3)\n",
        "\n",
        "# Train with MVP (q=2)\n",
        "alphas_mvp, stats_mvp = mvp_train(K_train_q3, ytr_svm, C=best_for_q3['C'], tol=1e-3, max_iter=200000)\n",
        "\n",
        "# get bias; averaging over free SVs gives a stable estimate\n",
        "b_mvp, sv_mask_mvp = compute_b(alphas_mvp, ytr_svm, K_train_q3, C=best_for_q3['C'])\n",
        "\n",
        "# Decision scores\n",
        "scores_train_mvp = (alphas_mvp*ytr_svm) @ K_train_q3 + b_mvp\n",
        "scores_test_mvp = (alphas_mvp*ytr_svm) @ K_test_q3 + b_mvp\n",
        "\n",
        "# Accuracies\n",
        "train_acc_mvp = float(np.mean((scores_train_mvp>=0).astype(int)==(y_train>0).astype(int)))\n",
        "test_acc_mvp  = float(np.mean((scores_test_mvp>=0).astype(int)==(y_test>0).astype(int)))\n",
        "\n",
        "# Print results\n",
        "print(f\"Kernel: {kernel_for_q3}\")\n",
        "print(f\"Hyperparameters: {best_for_q3}\")\n",
        "print(f\"Train accuracy: {train_acc_mvp:.4f}\")\n",
        "print(f\"Test  accuracy: {test_acc_mvp:.4f}\")\n",
        "print(f\"Support vectors: {int(np.sum(sv_mask_mvp))} / {len(ytr_svm)}\")\n",
        "\n",
        "print(\"\\nOptimization performance (MVP):\")\n",
        "print(f\"  Initial dual objective: {0.0:.6f}\") # at a=0 the dual is 0\n",
        "print(f\"  Final   dual objective: {stats_mvp['dual_obj']:.6f}\")\n",
        "print(f\"  Iterations (pair updates): {stats_mvp['iterations']}\")\n",
        "print(f\"  KKT violation at stop (b_low-b_up): {stats_mvp['kkt_gap']:.3e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
